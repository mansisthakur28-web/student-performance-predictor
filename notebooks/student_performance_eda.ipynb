{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Student Performance Predictor\n",
    "\n",
    "This notebook walks through the full ML pipeline:\n",
    "1. Data Loading\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Preprocessing\n",
    "4. Regression Modeling (predicting exam score)\n",
    "5. Classification Modeling (pass / fail)\n",
    "6. Feature Importance & Interpretation\n",
    "7. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# Ensure project root is on the path\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data_loader import load_data\n",
    "from src.preprocessing import (\n",
    "    prepare_data, add_pass_fail, get_feature_names,\n",
    "    NUMERIC_FEATURES, CATEGORICAL_FEATURES,\n",
    "    TARGET_REGRESSION, TARGET_CLASSIFICATION,\n",
    ")\n",
    "from src.model import (\n",
    "    train_regression_models, train_classification_models,\n",
    "    tune_model, save_model,\n",
    ")\n",
    "from src.evaluation import evaluate_regression, evaluate_classification, print_report\n",
    "from src.visualizations import (\n",
    "    plot_score_distribution, plot_correlation_heatmap,\n",
    "    plot_scatter_with_regression, plot_feature_importance,\n",
    "    plot_predicted_vs_actual, plot_confusion_matrix,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style='whitegrid', palette='muted', font_scale=1.1)\n",
    "print('âœ… All imports loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 Â· Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(PROJECT_ROOT, 'data', 'student_performance.csv')\n",
    "df = load_data(DATA_PATH)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape: {df.shape}')\n",
    "print(f'\\nData types:\\n{df.dtypes}')\n",
    "print(f'\\nMissing values:\\n{df.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 Â· Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_score_distribution(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_correlation_heatmap(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Scatter Plots with Regression Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_features = ['study_hours_per_week', 'attendance_rate', 'previous_exam_score', 'internal_marks']\n",
    "for feat in scatter_features:\n",
    "    fig = plot_scatter_with_regression(df, x=feat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Categorical Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "for ax, col in zip(axes.flatten(), CATEGORICAL_FEATURES):\n",
    "    sns.boxplot(data=df, x=col, y='final_exam_score', ax=ax, palette='muted')\n",
    "    ax.set_title(f'{col.replace(\"_\", \" \").title()} vs Final Score', weight='bold')\n",
    "    ax.tick_params(axis='x', rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 Â· Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression data\n",
    "X_train_r, X_test_r, y_train_r, y_test_r, preprocessor_r = prepare_data(\n",
    "    df, target=TARGET_REGRESSION\n",
    ")\n",
    "print(f'Regression split  â†’  Train: {X_train_r.shape[0]}  |  Test: {X_test_r.shape[0]}')\n",
    "\n",
    "# Classification data\n",
    "df_cls = add_pass_fail(df)\n",
    "print(f'\\nPass/Fail distribution:\\n{df_cls[TARGET_CLASSIFICATION].value_counts()}')\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c, preprocessor_c = prepare_data(\n",
    "    df_cls, target=TARGET_CLASSIFICATION\n",
    ")\n",
    "print(f'Classification split  â†’  Train: {X_train_c.shape[0]}  |  Test: {X_test_c.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 Â· Regression Modeling\n",
    "\n",
    "Predicting the **exact final exam score** using Linear Regression, Random Forest, and Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training regression models â€¦')\n",
    "reg_models = train_regression_models(X_train_r, y_train_r, preprocessor_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in reg_models.items():\n",
    "    metrics, y_pred = evaluate_regression(model, X_test_r, y_test_r)\n",
    "    print_report(name, metrics)\n",
    "    fig = plot_predicted_vs_actual(y_test_r, y_pred)\n",
    "    plt.suptitle(name, y=1.02, fontsize=13, weight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Hyperparameter Tuning (Random Forest Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from src.preprocessing import build_preprocessor\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('preprocessor', build_preprocessor()),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [None, 10, 20],\n",
    "    'model__min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "best_rf = tune_model(rf_pipe, param_grid, X_train_r, y_train_r, scoring='r2')\n",
    "\n",
    "metrics, y_pred = evaluate_regression(best_rf, X_test_r, y_test_r)\n",
    "print_report('Tuned Random Forest Regressor', metrics)\n",
    "\n",
    "# Save best regression model\n",
    "save_model(best_rf, os.path.join(PROJECT_ROOT, 'models', 'best_regressor.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5 Â· Classification Modeling\n",
    "\n",
    "Predicting **Pass / Fail** (threshold: 50) using Logistic Regression and Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training classification models â€¦')\n",
    "cls_models = train_classification_models(X_train_c, y_train_c, preprocessor_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in cls_models.items():\n",
    "    metrics, y_pred = evaluate_classification(model, X_test_c, y_test_c)\n",
    "    print_report(name, metrics)\n",
    "    fig = plot_confusion_matrix(metrics['Confusion Matrix'])\n",
    "    plt.suptitle(name, y=1.02, fontsize=13, weight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Save best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cls = cls_models['Random Forest Classifier']\n",
    "save_model(best_cls, os.path.join(PROJECT_ROOT, 'models', 'best_classifier.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6 Â· Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names from the fitted preprocessor\n",
    "fitted_preprocessor = best_rf.named_steps['preprocessor']\n",
    "feat_names = get_feature_names(fitted_preprocessor)\n",
    "\n",
    "fig = plot_feature_importance(best_rf, feat_names)\n",
    "if fig:\n",
    "    plt.suptitle('Regression â€” Feature Importance', y=1.02, fontsize=13, weight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_preprocessor_c = best_cls.named_steps['preprocessor']\n",
    "feat_names_c = get_feature_names(fitted_preprocessor_c)\n",
    "\n",
    "fig = plot_feature_importance(best_cls, feat_names_c)\n",
    "if fig:\n",
    "    plt.suptitle('Classification â€” Feature Importance', y=1.02, fontsize=13, weight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7 Â· Summary & Next Steps\n",
    "\n",
    "| Task | Best Model | Key Metric |\n",
    "|------|-----------|------------|\n",
    "| Score Prediction | Tuned Random Forest | RÂ² (see above) |\n",
    "| Pass/Fail | Random Forest Classifier | F1 / ROC-AUC (see above) |\n",
    "\n",
    "### Next steps\n",
    "- Launch the **Streamlit app** for interactive predictions: `streamlit run app/streamlit_app.py`\n",
    "- Collect user feedback via the in-app form\n",
    "- Experiment with additional features or real-world datasets\n",
    "- Perform fairness audits across demographic groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
